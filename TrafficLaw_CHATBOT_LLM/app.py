import streamlit as st
from services.ollama_client import OllamaClient
from services.rag_engine import RAGEngine

# Streamlit config
st.set_page_config(page_title="Traffic Laws Decree 168 Chatbot (Local LLM)", page_icon="ğŸ“œ")

SYSTEM_PROMPT = """Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh, chuyÃªn gia vá» Luáº­t Giao thÃ´ng ÄÆ°á»ng bá»™ Viá»‡t Nam, Ä‘áº·c biá»‡t lÃ  Nghá»‹ Ä‘á»‹nh 168/2024/NÄ-CP.

NguyÃªn táº¯c báº¯t buá»™c:
1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin cÃ³ trong cÃ¡c Ä‘oáº¡n vÄƒn báº£n Ä‘Æ°á»£c cung cáº¥p (context).
2. KhÃ´ng Ä‘Æ°á»£c suy luáº­n, khÃ´ng bá»• sung kiáº¿n thá»©c bÃªn ngoÃ i Nghá»‹ Ä‘á»‹nh 168.
3. Náº¿u khÃ´ng tÃ¬m tháº¥y quy Ä‘á»‹nh phÃ¹ há»£p, pháº£i tráº£ lá»i rÃµ: 
   "Nghá»‹ Ä‘á»‹nh 168 khÃ´ng quy Ä‘á»‹nh cá»¥ thá»ƒ trÆ°á»ng há»£p nÃ y."
4. Khi tráº£ lá»i vá» má»©c pháº¡t, pháº£i nÃªu rÃµ:
   - TrÃ­ch dáº«n tá»« vÄƒn báº£n theo cáº¥u trÃºc "ChÆ°Æ¡ng > Má»¥c > Äiá»u > Khoáº£n > Äiá»ƒm":
        + ChÆ°Æ¡ng (vÃ­ dá»¥ ChÆ°Æ¡ng I, ChÆ°Æ¡ng II, v.v.)
        + Má»¥c (náº¿u cÃ³, vÃ­ dá»¥ Má»¥c 1, Má»¥c 2, v.v.)
        + Äiá»u (vÃ­ dá»¥: Äiá»u 1, Äiá»u 2, v.v.) 
        + Khoáº£n (vÃ­ dá»¥ 1, 2, 3, v.v.)
        + Äiá»ƒm (vÃ­ dá»¥ a, b, c, v.v.)
   - Äá»‘i tÆ°á»£ng Ã¡p dá»¥ng (loáº¡i phÆ°Æ¡ng tiá»‡n)
   - Má»©c pháº¡t chÃ­nh xÃ¡c
5. KhÃ´ng Ä‘Æ°a ra lá»i khuyÃªn cÃ¡ nhÃ¢n hay Ä‘Ã¡nh giÃ¡ chá»§ quan.
6. NgÃ´n ngá»¯ rÃµ rÃ ng, trung láº­p, dá»… hiá»ƒu.

CÃ¡ch tráº£ lá»i:
- Æ¯u tiÃªn liá»‡t kÃª theo gáº¡ch Ä‘áº§u dÃ²ng.
- TrÃ­ch dáº«n Ä‘iá»u khoáº£n theo dáº¡ng: 
  "Theo Äiá»u X, Khoáº£n Y Nghá»‹ Ä‘á»‹nh 168..."
- KhÃ´ng sá»­ dá»¥ng cÃ¡c cá»¥m tá»« phá»ng Ä‘oÃ¡n nhÆ° "cÃ³ thá»ƒ", "thÆ°á»ng lÃ ", "nhiá»u kháº£ nÄƒng".

Náº¿u cÃ¢u há»i khÃ´ng rÃµ thÃ´ng tin (vÃ­ dá»¥: loáº¡i phÆ°Æ¡ng tiá»‡n, hÃ nh vi cá»¥ thá»ƒ),
hÃ£y yÃªu cáº§u ngÆ°á»i há»i cung cáº¥p thÃªm thÃ´ng tin cáº§n thiáº¿t trÆ°á»›c khi tráº£ lá»i.

"""

# Init client
@st.cache_resource
def get_resources():
    client = OllamaClient(model_name="llama3.2")
    rag = RAGEngine()
    return client, rag
    
client, rag = get_resources()

st.title("ğŸš¦ Traffic Laws Decree 168 Q&A Chatbot")
st.write("Powered by Local Ollama3.2 + RAG")

# Build RAG button
if st.button("ğŸ”„ Build Knowledge Base (RAG)"):
    rag.build()
    st.success("âœ… Knowledge base built successfully!")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display old messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# User input
user_input = st.chat_input("ğŸš¦ Nháº­p cÃ¢u há»i cá»§a báº¡n vá» luáº­t giao thÃ´ng (nghá»‹ Ä‘á»‹nh 168)...")

if user_input:
    # Save user message
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # Model reply with RAG
    with st.chat_message("assistant"):

        # RAG augmentation
        related_chunks = rag.search(user_input)
        context = "\n\n".join(related_chunks)
        print("RAG Context:", context)
        with st.expander("ğŸ RAG Retrieved Context (debug)"):
            st.write(context)

        full_prompt = f"""
DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ thÃ´ng tin tá»« tÃ i liá»‡u luáº­t giao thÃ´ng (nghá»‹ Ä‘á»‹nh 168):

{context}

Dá»±a trÃªn thÃ´ng tin nÃ y, tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng:
{user_input}
"""

        reply = client.ask(SYSTEM_PROMPT, full_prompt)
        st.write(reply)

    # Save assistant message
    st.session_state.messages.append({"role": "assistant", "content": reply})